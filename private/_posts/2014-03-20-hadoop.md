---
---

# Hadoop实践

## 工作环境
```
sudo -H -u spider bash
export LC_ALL=zh_CN.UTF-8
cd /home/spider/wangwenming/
cat paths
```

## 例子
1. `mapper.sh`
```
#!/bin/bash

grep "pro=se_suggest&pid=recom-nlp&abv=Entity_Popup&.*&formal=1.*&session="
# 忽略grep失败的节点
if [ $? != 0 ]; then
    exit 0
fi
```

2. `reducer.sh`
```
#!/bin/bash

awk 'BEGIN{sum=0;sum_popup=0;} /session=picture/{sum+=1} /session=popup/{sum_popup+=1} END{print sum"\t"sum_popup}'
```

3. streaming 脚本
```
#!/bin/bash

name="wangwenming_EntityPopupSrp"
input="/home/maintable/data/qss_engine_log/webdotlog/`date "+%Y%m%d" -d '-1 day'`/so_srp-*.gz"
output="/home/spider/output/tmp/${name}"
mapper="mapper.sh"
reducer="reducer.sh"

echo $input

# 必须删除，不能覆盖
hadoop fs -rmr "${output}"

# 使用 -D，否则报 WARN => 14/03/20 15:53:03 WARN streaming.StreamJob: -jobconf option is deprecated, please use -D instead.
# jobconf 所有参数参考： http://longmans1985.blog.163.com/blog/static/70605475201159343564/
#    -D mapred.reduce.tasks=0 \
#    -D stream.non.zero.exit.is.failure=false \
#    -D stream.num.map.output.key.fields=2 \

# 统计展现PV
hadoop jar jar/hadoop-0.20.1.12-fb-streaming.jar \
    -D mapred.job.name="${name}" \
    -D mapred.job.priority=VERY_HIGH \
    -D stream.non.zero.exit.is.failure=false \
    -input ${input} \
    -output ${output} \
    -file "${mapper}" \
    -file "${reducer}" \
    -mapper "sh ${mapper}" \
    -reducer "sh ${reducer}"
```

## `-file`参数解释： http://blog.csdn.net/yfkiss/article/details/6399874
>如果程序运行所需要的可执行文件、脚本或者配置文件在Hadoop集群的*计算节点*上不存在，则首先需要将这些文件分发到集群上才能成功进行计算。
`PipeMapRed.waitOutputThreads(): subprocess failed with code X`
>127/255:一般是由于map/reduce脚本未上传导致，请使用-file 上传map/reduce程序
`PipeMapRed.waitOutputThreads(): subprocess failed with code 1`
>1:map/reduce程序返回值部位*0*，比如grep匹配失败


## 状态页面： http://182.118.41.5:50030/cm.jsp

## `hadoop fs` 的所有命令，用`hadoop fs help`查看

## 其他
1. `echo $HADOOP_HOME` => `/home/work/software/hadoop/`
2. `gzip -d zzz.gz`
